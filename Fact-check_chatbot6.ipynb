{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fact-check chatbot\n",
    "\n",
    "First load all the API keys and choose an llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\OneDrive\\Documenten\\OU\\Graduation\\checkmate\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\", override=True)\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"]=\"pr-left-technician-100\"\n",
    "\n",
    "llm = ChatOllama(model=\"qwen3:4b\", temperature=0.2, base_url=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Faiss database, and set up as retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Load existing FAISS index\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "vectorstore = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Set up retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a retriever tool, one that also checks the article behind the url, since only the url resides in the database. Furthermore the url's are seperated in ALLOWED URL's to ensure that the exact url is cited. This to prevent hallucinated url's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--{'retriever_tool': StructuredTool(name='retriever_tool', description='This tool searches and returns information from the FACTors dataset.\\nIt returns two blocks as one string:\\n1) CONTEXT: numbered snippets without URLs\\n2) ALLOWED_URLS: a JSON dictionary of index -> url that the model must cite by index only', args_schema=<class 'langchain_core.utils.pydantic.retriever_tool'>, func=<function retriever_tool at 0x0000017A7627F240>)}--\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from newspaper import Article\n",
    "import json\n",
    "\n",
    "# ──────────────────────────────\n",
    "# HELPER FUNCTION TO FETCH FULL ARTICLE CONTENT\n",
    "# ──────────────────────────────\n",
    "def fetch_full_article(url) -> tuple[str, bool]:\n",
    "    \"\"\"\n",
    "    Fetch and return the full text of an article from a given URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        return article.text, True\n",
    "    except Exception as e:\n",
    "        return f\"[Failed to fetch article content from {url}: {e}]\", False\n",
    "\n",
    "#set a limit to the number of characters from the full article\n",
    "max_chars = 1200\n",
    "\n",
    "# ──────────────────────────────\n",
    "# HELPER FUNCTION TO COMBINE SUMMARY AND FULL ARTICLE CONTENT, AND SEPERATE URLS\n",
    "# ──────────────────────────────\n",
    "def format_docs(docs) -> str:\n",
    "    \"\"\"\n",
    "    Format the found documents to format\n",
    "    \"\"\"\n",
    "    formatted = []\n",
    "    for i, d in enumerate(docs, start=0):\n",
    "        summary = (d.page_content or \"\").strip()\n",
    "        url = d.metadata.get(\"url\", \"\")\n",
    "        full_content, page_exsists = fetch_full_article(url)\n",
    "        \n",
    "        #rerturn content only if the page exsists \n",
    "        if page_exsists:\n",
    "            if len(full_content) > max_chars:\n",
    "                full_content = full_content[:max_chars] + \"…\"\n",
    "            combined = f\"\"\"\n",
    "            [{i}] SUMMARY:\n",
    "            {summary}\n",
    "\n",
    "            [{i}] FULL ARTICLE CONTENT:\n",
    "            {full_content}\n",
    "            \"\"\"\n",
    "            formatted.append(combined)\n",
    "        else:\n",
    "            formatted.append(f\"this url: {url} does not exist, don't use it in your answer\")\n",
    "    return \"\\n\\n---\\n\\n\".join(formatted)\n",
    "\n",
    "@tool\n",
    "# ──────────────────────────────\n",
    "# TOOL FUNCTION  TO SEARCH FACTors DATASET, RETURN CONTEXT + ALLOWED_URLS\n",
    "# ──────────────────────────────\n",
    "def retriever_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    This tool searches and returns information from the FACTors dataset.\n",
    "    It returns two blocks as one string:\n",
    "    1) CONTEXT: numbered snippets without URLs\n",
    "    2) ALLOWED_URLS: a JSON dictionary of index -> url that the model must cite by index only\n",
    "    \"\"\"\n",
    "    print(f\"\\n--retriever called, query: {query}--\\n\")\n",
    "    docs = retriever.invoke(query)\n",
    "    context_block = format_docs(docs)\n",
    "\n",
    "    # Build a list of allowed URLs, and index them.\n",
    "    urls = [d.metadata.get(\"url\", \"\") for d in docs if d.metadata.get(\"url\")]\n",
    "    allowed = dict(enumerate(urls))\n",
    "    print(f\"Allowed URLs: {allowed}\")\n",
    "\n",
    "    # Return a single string so your existing tool plumbing still works.\n",
    "    return (\n",
    "        \"CONTEXT (read-only; do NOT copy or invent URLs):\\n\"\n",
    "        f\"{context_block}\\n\\n\"\n",
    "        \"ALLOWED_URLS (index -> url):\\n\"\n",
    "        f\"{json.dumps(allowed, indent=2)}\\n\\n\"\n",
    "        \"INSTRUCTIONS: When citing, use indices from ALLOWED_URLS only (e.g., [0], [2]). \"\n",
    "        \"Do not output raw URLs unless they come from ALLOWED_URLS.\"\n",
    "    )\n",
    "\n",
    "# Add the retriever tool to tools and bind the tool to the LLM\n",
    "tools = [retriever_tool]\n",
    "llm_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Creating a dictionary of our tools\n",
    "tools_dict = {our_tool.name: our_tool for our_tool in tools} \n",
    "print(f\"\\n--{tools_dict}--\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part determines which data should be stored in AgentState (memory of the program), and how certain output should be structured using pydantic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence, Literal, List\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from operator import add as add_messages\n",
    "\n",
    "# Define the structure of a citation\n",
    "class Citation(TypedDict):\n",
    "    index: str\n",
    "    url: str\n",
    "    title: str\n",
    "    passage: str\n",
    "\n",
    "# Create an object to hold the state of the agent\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    claim: str\n",
    "    checkable: bool\n",
    "    verdict: Literal[\"true\", \"false\", \"mixed\", \"insufficient\"]\n",
    "    explanation: str\n",
    "    citations: List[Citation]\n",
    "    follow_up_Q: str\n",
    "\n",
    "\n",
    "#output models for structured output\n",
    "class Checkability(BaseModel):\n",
    "    checkable: bool = Field(..., description=\"True if the claim is checkable, else false.\")\n",
    "    explanation: str = Field(..., min_length=1, description=\"Short justification for the decision.\")\n",
    "\n",
    "parser_checkability = PydanticOutputParser(pydantic_object=Checkability)\n",
    "format_checkability = parser_checkability.get_format_instructions()\n",
    "\n",
    "class FactCheckResult(BaseModel):\n",
    "    verdict: Literal[\"TRUE\", \"FALSE\", \"MOSTLY TRUE\", \"MOSTLY FALSE\",\"UNCHECKABLE\"]\n",
    "    explanation: str\n",
    "    citations: List[Citation]\n",
    "\n",
    "parser_fact_check = PydanticOutputParser(pydantic_object=FactCheckResult)\n",
    "format_fact_check = parser_fact_check.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions of all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage,AIMessage\n",
    "\n",
    "# ──────────────────────────────\n",
    "# NODE FUNCTION TO CHECK IF THE CLAIM is CHECKABLE\n",
    "# ──────────────────────────────\n",
    "def check_fact_checkability(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Check if a claim is checkable.\n",
    "    \"\"\"\n",
    "    # Use structured output to get a boolean and explanation as output\n",
    "    structured_llm = llm.with_structured_output(Checkability)\n",
    "\n",
    "    # System prompt for checkability\n",
    "    checkability_prompt = f\"\"\"\n",
    "    Task:\n",
    "    Decide if a single claim is CHECKABLE (factual, verifiable) or UNCHECKABLE (opinion, prediction, or too vague).\n",
    "\n",
    "    Definitions:\n",
    "    CHECKABLE: The claim asserts something that can be verified with evidence (e.g., data, records, studies), even without exact numbers or precise details.\n",
    "    UNCHECKABLE: The claim is an opinion, value judgment, future prediction, or too vague to investigate.\n",
    "\n",
    "    Rules:\n",
    "    -Evidence link: If the claim refers to a measurable property or documentable fact, mark CHECKABLE. Lack of an exact figure does not disqualify it.\n",
    "    -Comparisons: “More/less,” “higher/lower,” etc. are CHECKABLE if the attribute is measurable.\n",
    "    -Clarity: If subject + attribute are specific enough that a journalist could look them up, it’s CHECKABLE. If too vague, UNCHECKABLE.\n",
    "    -Future claims: Predictions are always UNCHECKABLE.\n",
    "    -Value judgments: Normative or taste claims (“better,” “should,” “harmful”) are UNCHECKABLE, unless they define a measurable outcome.\n",
    "\n",
    "    Examples:\n",
    "    “Omicron spreads faster than other Covid-19 strains.” → CHECKABLE\n",
    "    “Chocolate ice cream is better than vanilla.” → UNCHECKABLE\n",
    "    “Unemployment was higher in 2023 than 2022.” → CHECKABLE\n",
    "    “The stock market will crash next month.” → UNCHECKABLE\n",
    "    “City X has more residents than City Y.” → CHECKABLE\n",
    "    “This policy is harmful.” → UNCHECKABLE unless linked to specific metrics.\n",
    "\n",
    "    {format_checkability}\n",
    "    \"\"\"\n",
    "    msgs = [\n",
    "        SystemMessage(content=checkability_prompt),\n",
    "        HumanMessage(content=f'Claim: \"{state[\"claim\"]}\"'),\n",
    "    ]\n",
    "\n",
    "    result: Checkability = structured_llm.invoke(msgs)\n",
    "\n",
    "    # print output\n",
    "    print(\"\\n=== 1. CHECKABLE? ===\")\n",
    "    print(f\"{result.checkable}\")\n",
    "    print(f\"{result.explanation}\")\n",
    "    \n",
    "    # Add the model's response as an AIMessage for traceability\n",
    "    ai_msg = AIMessage(content=result.model_dump_json())\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"checkable\": result.checkable,\n",
    "        \"messages\": list(state.get(\"messages\", [])) + [ai_msg],\n",
    "    }\n",
    "\n",
    "# ─────────────────────────────\n",
    "# CONDITIONAL FUNCTION: IF CHECKABLE -> CONTINUE\n",
    "# ──────────────────────────────\n",
    "def branch_on_checkable(state: AgentState) -> bool:\n",
    "        return state.get(\"checkable\")\n",
    "\n",
    "# ─────────────────────────────\n",
    "# NODE FUNCTION TO GATHER MORE EVIDENCE\n",
    "# ──────────────────────────────\n",
    "def research(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Call the tools iteratively (retriever tool) to gather evidence about the claim. \n",
    "    Add this evidence to the conversation history. \n",
    "    \"\"\"\n",
    "    claim = state.get(\"claim\", \"\")\n",
    "\n",
    "    # System prompt for research\n",
    "    research_prompt = f\"\"\"\n",
    "    INSTRUCTIONS\n",
    "    - Call `retriever_tool` with short, focused queries directly about the {claim} (population, exposure, outcome, timeframe),\n",
    "    or if the last HumanMessag is a \"Follow up question\" focus on this question.\n",
    "    - Reformulate and call again ONLY if needed. Do not ask unrelated trivia.\n",
    "    - Use retrieved CONTEXT and ALLOWED_URLS to decide if you need more queries.\n",
    "    - Do NOT produce a final verdict or JSON in this turn.\n",
    "    - When you have enough, stop calling tools and give a brief, ordinary reply (e.g., \"Proceed to finalize\").\n",
    "    \"\"\"\n",
    "    msgs = [\n",
    "        SystemMessage(content=research_prompt),\n",
    "        HumanMessage(content=\"If you need evidence, call `retriever_tool` with a focused query, relevant to the claim.\")\n",
    "    ]\n",
    "    messages = list(state.get(\"messages\", [])) + msgs\n",
    "\n",
    "    # Iteratively call tools until done, use llm_tools to enable tool calling\n",
    "    while True:\n",
    "        ai = llm_tools.invoke(messages) \n",
    "        print(f\"AI Response: {ai.content}\\n\")\n",
    "        messages.append(ai)\n",
    "\n",
    "        # check if there are tool calls\n",
    "        tc = getattr(ai, \"tool_calls\", None)\n",
    "        if not tc:\n",
    "            break\n",
    "\n",
    "        # run tools and append ToolMessages\n",
    "        tool_msgs = []\n",
    "        for t in tc:\n",
    "            out = tools_dict[t[\"name\"]].invoke(t[\"args\"].get(\"query\", \"\"))\n",
    "            tool_msgs.append(ToolMessage(tool_call_id=t[\"id\"], name=t[\"name\"], content=str(out)))\n",
    "        messages += tool_msgs\n",
    "\n",
    "    return {**state, \"messages\": messages}\n",
    "\n",
    "# ─────────────────────────────\n",
    "# NODE FUNCTION TO STRUCTURE FINAL OUTPUT\n",
    "# ──────────────────────────────\n",
    "def finalize(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Finalize the fact-check by producing a verdict, explanation, and citations based on all retrieved evidence. \n",
    "    Use structured output to ensure the response is in the correct format.\n",
    "    \"\"\"\n",
    "    claim = state.get(\"claim\", \"\")\n",
    "\n",
    "    # System prompt for finalization\n",
    "    finalize_prompt = f\"\"\"\n",
    "    You are finalizing a fact-check for the claim: \"{claim}\".\n",
    "\n",
    "    You must rely ONLY on evidence already retrieved (CONTEXT and ALLOWED_URLS from prior tool calls in the conversation). \n",
    "    Do NOT call any tools now.\n",
    "\n",
    "    VERDICTS\n",
    "    - TRUE / FALSE/ MOSTLY TRUE / MOSTLY FALSE / UNCHECKABLE\n",
    "    \n",
    "    RULES\n",
    "    - Match metric, population, geography, and timeframe.\n",
    "    - Prefer primary/official sources; explain conflicts briefly.\n",
    "    - Cite passages ≤40 words and reference sources by ALLOWED_URLS index only (e.g., \"0\", \"2\").\n",
    "    - Include the urls from ALLOWED_URLS in your citations.\n",
    "\n",
    "    {format_fact_check}\n",
    "    \"\"\"\n",
    "\n",
    "    #use structured output to get a verdict eplanation and citations from ALLOWED_URLS\n",
    "    structured_llm = llm.with_structured_output(FactCheckResult)\n",
    "\n",
    "    msgs = list(state.get(\"messages\", [])) + [\n",
    "        SystemMessage(content=finalize_prompt),\n",
    "        HumanMessage(content=\"Return ONLY the JSON for the final verdict based on retrieved evidence.\")\n",
    "    ]\n",
    "    result: FactCheckResult = structured_llm.invoke(msgs)\n",
    "\n",
    "    # print output\n",
    "    print(\"\\n=== 2. ANSWER ===\")\n",
    "    print(f\"{result.verdict}\")\n",
    "    print(f\"{result.explanation}\")\n",
    "    for citation in result.citations:\n",
    "        print(f\"[{citation['index']}] {citation['title']}\")\n",
    "        print(f\"URL: {citation['url']}\")\n",
    "        print(f\"Passage: {citation['passage']}\\n\")\n",
    "   \n",
    "\n",
    "    ai_msg = AIMessage(content=result.model_dump_json())\n",
    "    return {\n",
    "        **state,\n",
    "        \"verdict\": result.verdict,\n",
    "        \"explanation\": result.explanation,\n",
    "        \"citations\": result.citations,\n",
    "        \"messages\": list(state.get(\"messages\", [])) + [ai_msg],\n",
    "    }\n",
    "\n",
    "# ─────────────────────────────\n",
    "# CONDITIONAL FUNCTION: IF FOLLOW UP -> REPEAT FLOW\n",
    "# ──────────────────────────────\n",
    "def follow_up(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Check if the user has a follow-up question.\n",
    "    \"\"\"\n",
    "    user_input = input(\"\\nDo you have a follow-up question? (yes (y) /no (n)): \")\n",
    "\n",
    "    if user_input == 'yes' or user_input == 'y':\n",
    "        # if the user has a follow-up question, get the question and add it to the messages\n",
    "        user_followup=input(\"\\nWhat is your question? : \")\n",
    "        return {\n",
    "            **state,\n",
    "            \"follow_up_Q\": user_followup,\n",
    "            \"messages\": list(state.get(\"messages\", [])) + [HumanMessage(content=\"follow up question: \"+user_followup)],\n",
    "        }       \n",
    "    else:\n",
    "        print(\"No follow-up question. Ending the fact-checking process.\")\n",
    "        return {**state,\n",
    "                \"follow_up_Q\": None,\n",
    "        }\n",
    "    \n",
    "    # ─────────────────────────────\n",
    "# CONDITIONAL FUNCTION: IF FOLLOW-UP -> CONTINUE\n",
    "# ──────────────────────────────\n",
    "def branch_on_follow_up(state: AgentState) -> bool:\n",
    "    if state.get(\"follow_up_Q\")==None:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the langgraph nodes and edges, and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"check_fact_checkability\", check_fact_checkability)\n",
    "graph.add_node(\"research\", research)          # tools handled internally (loop inside research)\n",
    "graph.add_node(\"finalize\", finalize)          # structured, no tools\n",
    "graph.add_node(\"follow_up_question\", follow_up)\n",
    "\n",
    "# If checkable → research, else end\n",
    "graph.add_conditional_edges(\n",
    "    \"check_fact_checkability\",\n",
    "    branch_on_checkable,\n",
    "    {True: \"research\", False: END}\n",
    ")\n",
    "\n",
    "# After research, go finalize\n",
    "graph.add_edge(\"research\", \"finalize\")\n",
    "\n",
    "# After finalize, offer follow-up\n",
    "graph.add_edge(\"finalize\", \"follow_up_question\")\n",
    "\n",
    "# If user has a follow-up → back to research, else end\n",
    "graph.add_conditional_edges(\n",
    "    \"follow_up_question\",\n",
    "    branch_on_follow_up,\n",
    "    {True: \"research\", False: END}\n",
    ")\n",
    "\n",
    "# Entry point\n",
    "graph.add_edge(START, \"check_fact_checkability\")\n",
    "\n",
    "fact_bot = graph.compile()\n",
    "\n",
    "#visualization\n",
    "#from IPython.display import Image, display\n",
    "#display(Image(fact_bot.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the agent in iterations, prompting the user everytime and log the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAIM: An Oxfam report in 2024 found $41 billion missing from the World Bank's climate fund\n",
      "\n",
      "=== 1. CHECKABLE? ===\n",
      "True\n",
      "The claim refers to a specific report (Oxfam) from a specific year (2024) and a specific amount ($41 billion) that can be verified through the report itself or its official documentation. The existence of such a report with these details is a factual claim that can be checked against the report's publication or related records.\n",
      "AI Response: <think>\n",
      "Okay, let's see. The user mentioned that an Oxfam report in 2024 found $41 billion missing from the World Bank's climate fund. They want me to check if this is true.\n",
      "\n",
      "First, I need to use the retriever_tool to get information about this specific report. The query should be focused on the population, exposure, outcome, and timeframe as per the instructions. The user said to call the tool with short, focused queries directly about the An Oxfam report in 2024 found $41 billion missing from the World Bank's climate fund.\n",
      "\n",
      "Wait, the problem says to call retriever_tool with queries about population, exposure, outcome, timeframe. But the original claim is about the report finding $41 billion missing. So maybe the query should be something like \"Oxfam 2024 report World Bank climate fund $41 billion missing\".\n",
      "\n",
      "But the instructions say to focus on population, exposure, outcome, timeframe. Let me think. The user's claim is that the report found $41 billion missing. So the outcome here is the missing amount, the timeframe is 2024, the fund is World Bank's climate fund. Population might refer to how many people are affected, but the claim doesn't mention population. Exposure could be the number of people or entities exposed to the missing funds.\n",
      "\n",
      "Wait, the user's instruction says: \"Call `retriever_tool` with short, focused queries directly about the An Oxfam report in 2024 found $41 billion missing from the World Bank's climate fund (population, exposure, outcome, timeframe)\".\n",
      "\n",
      "So the query should be structured to get info on those four aspects. But the user's claim is about the outcome (the $41 billion missing), timeframe (2024), and maybe the fund (World Bank climate fund). Population and exposure might not be directly mentioned in the claim, but the tool needs to retrieve context.\n",
      "\n",
      "I should construct a query that targets the specific report. Let me try: \"Oxfam 2024 report World Bank climate fund $41 billion missing\".\n",
      "\n",
      "Wait, the tool's description says it returns CONTEXT and ALLOWED_URLS. So I need to make a query that's specific enough to get the relevant info.\n",
      "\n",
      "The user's previous message was the same as the initial claim, so I need to call the retriever_tool with a query that focuses on the report details. Let me check the allowed URLs. But since I don't have the actual URLs, I'll just make the query.\n",
      "\n",
      "The correct query here is probably \"Oxfam 2024 report missing $41 billion from World Bank climate fund\" to get the context. Let me structure it as a short, focused query.\n",
      "\n",
      "So the tool call would be retriever_tool with query: \"Oxfam 2024 report $41 billion missing from World Bank climate fund\".\n",
      "\n",
      "Yes, that's specific and covers the key points. Let me make sure it's short and focused. The user wants population, exposure, outcome, timeframe. The outcome here is the $41 billion missing, timeframe is 2024. The report might mention population and exposure in the context.\n",
      "\n",
      "So I'll generate the tool call with that query.\n",
      "</think>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--retriever called, query: Oxfam 2024 report $41 billion missing from World Bank climate fund--\n",
      "\n",
      "Allowed URLs: {0: 'https://www.aap.com.au/factcheck/charity-report-did-not-find-world-bank-climate-change-fund-was-missing-41-billion/', 1: 'https://www.aap.com.au/factcheck/world-bank-is-not-missing-41-billion-in-climate-funds-despite-claims/', 2: 'https://digiteye.in/has-41-billion-climate-fund-gone-missing-from-world-bank-under-ajay-banga-fact-check/', 3: 'https://www.aap.com.au/factcheck/2-trillion-climate-fund-claim-a-red-hot-lie/'}\n",
      "AI Response: <think>\n",
      "Okay, let's see. The user wants to know if the claim that an Oxfam report in 2024 found $41 billion missing from the World Bank's climate fund is true.\n",
      "\n",
      "First, I checked the retrieved context. There are four entries. Let me go through each.\n",
      "\n",
      "Entry [0] from AAP says the claim is false. The World Bank doesn't have a single \"climate fund\", and Oxfam didn't find funds missing. The report they analyzed was from 2017-2023, and the missing $41 billion claim is incorrect.\n",
      "\n",
      "Entry [1] also states the verdict is false. Same reasoning: no single climate fund, Oxfam didn't find missing funds.\n",
      "\n",
      "Entry [2] mentions that Oxfam's report covered 2017/18 to 2022/23, which is before Ajay Banga's tenure started. So the claim that it's under his watch is wrong.\n",
      "\n",
      "Entry [3] is about a different claim (Australia's $2 trillion commitment), so it's not relevant here.\n",
      "\n",
      "The key points from the context: The Oxfam report didn't find missing funds; the World Bank doesn't have a single climate fund. The $41 billion figure is part of a social media claim that's been debunked by fact-checkers.\n",
      "\n",
      "So the answer should be that the claim is false based on the retrieved context. The user probably needs a concise response confirming the falsehood with the sources from the context.\n",
      "</think>\n",
      "\n",
      "Proceed to finalize\n",
      "\n",
      "\n",
      "=== 2. ANSWER ===\n",
      "FALSE\n",
      "The World Bank does not have a single 'climate fund', and Oxfam's Climate Finance Unchecked report (2017-2023) found no missing funds but rather a lack of tracking for project components labeled 'climate finance' during approval. The claim originated from a social media post by Brian Tamaki, which was debunked by AAP FactCheck using Oxfam's report data.\n",
      "[0] Charity report did not find World Bank climate change fund was missing $41 billion\n",
      "URL: https://www.aap.com.au/factcheck/charity-report-did-not-find-world-bank-climate-change-fund-was-missing-41-billion/\n",
      "Passage: The World Bank does not have a single 'climate fund', and Oxfam did not find funds were 'missing'.\n",
      "\n",
      "[1] World Bank is not missing $41 billion in climate funds, despite claims\n",
      "URL: https://www.aap.com.au/factcheck/world-bank-is-not-missing-41-billion-in-climate-funds-despite-claims/\n",
      "Passage: The World Bank does not have a single 'climate fund', and Oxfam did not find that funds are 'missing'.\n",
      "\n",
      "No follow-up question. Ending the fact-checking process.\n",
      "Conversation saved to logging.txt\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "\n",
    "def running_agent():\n",
    "\n",
    "    conversation_history: List[BaseMessage] = []\n",
    "    while True:\n",
    "        user_input = input(\"\\nWhat claim do you want to investigate? \")\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            break\n",
    "\n",
    "        print(f\"CLAIM: {user_input}\")\n",
    "\n",
    "        # Build full AgentState for this turn\n",
    "        state: AgentState = {\n",
    "            \"messages\": conversation_history + [HumanMessage(content=user_input)],\n",
    "            \"claim\": user_input,\n",
    "            \"checkable\": None, \n",
    "            \"verdict\": None,\n",
    "            \"explanation\": None,\n",
    "            \"citations\": None,\n",
    "            \"follow_up_Q\": None,\n",
    "        }\n",
    "\n",
    "        # Invoke the compiled LangGraph app (your graph)\n",
    "        result = fact_bot.invoke(state)\n",
    "\n",
    "        # Update the rolling conversation history with everything the graph returned\n",
    "        conversation_history = list(result[\"messages\"])\n",
    "\n",
    "        # Optional: react to checkability if you want to surface it explicitly\n",
    "        if result.get(\"checkable\") is False:\n",
    "            print(\"\\n(Stopped: claim judged UNCHECKABLE.)\")\n",
    "\n",
    "    # Persist a readable log\n",
    "    with open(\"logging.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Your Conversation Log:\\n\")\n",
    "        for m in conversation_history:\n",
    "            if isinstance(m, HumanMessage):\n",
    "                f.write(f\"You: {m.content}\\n\")\n",
    "            elif isinstance(m, AIMessage):\n",
    "                f.write(f\"AI: {m.content}\\n\\n\")\n",
    "        f.write(\"End of Conversation\\n\")\n",
    "\n",
    "    print(\"Conversation saved to logging.txt\")\n",
    "\n",
    "# run it\n",
    "running_agent()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
