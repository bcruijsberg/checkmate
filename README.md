# CheckMate â™Ÿï¸  
*A Multi-Agent Fact-Checking Assistant for Journalism Education*

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-App-red)
![LangGraph](https://img.shields.io/badge/LangGraph-Multi--Agent-purple)
![FAISS](https://img.shields.io/badge/FAISS-Vector%20Store-green)
![Status](https://img.shields.io/badge/Status-Prototype-orange)

---

## ğŸ§­ Overview

**CheckMate** is a **research prototype multi-agent assistant** designed to support **journalism students** in learning and practicing **fact-checking**.

The system is grounded in the educational workflows developed by the **EUfactcheck project**  
(https://eufactcheck.eu), which were explicitly designed for **journalism education**.

Rather than merely automating fact-checking steps, CheckMate aims to:

- Teach **structured and transparent fact-checking workflows**
- Encourage **critical reasoning and reflection**

To achieve this, the assistant generates **critical, Socratic-style questions** at key stages of the workflow.  
These questions are intended to be discussed with peers in **oral or written reflective assignments**, encouraging students to reflect not only on *what* they conclude, but *why*.

Technically, CheckMate is implemented using the **LangGraph framework** and integrates a **FAISS vector store** for retrieval-augmented reasoning over fact-checking datasets.

---

## ğŸ¥ Demo Video

Watch the demo on YouTube: https://www.youtube.com/watch?v=FgR_dnYQu9s

[![CheckMate demo video thumbnail](https://img.youtube.com/vi/FgR_dnYQu9s/hqdefault.jpg)](https://www.youtube.com/watch?v=FgR_dnYQu9s)

---

## ğŸ“š FACTors Dataset

Training and evaluation data were grounded in **real-world fact-checking claims** from the **FACTors project**, a large-scale dataset for studying the fact-checking ecosystem.

- FACTors GitHub repository:  
  ğŸ‘‰ https://github.com/altuncu/FACTors

Synthetic training data was generated by transforming FACTors claims into **Socratic questions**, enabling the models to learn reflective, pedagogically oriented questioning behavior.

---
## ğŸ“ Repository Structure

```text
.
â”œâ”€â”€ app.py                          # Main Streamlit interface and graph initialization
â”œâ”€â”€ src/                            # Core application code
â”‚   â”œâ”€â”€ State_scope.py              # AgentState and Pydantic data models
â”‚   â”œâ”€â”€ claim_nodes.py              # LangGraph node implementations
â”‚   â”œâ”€â”€ prompts.py                  # Prompt templates
â”‚   â”œâ”€â”€ tooling.py                  # LLMs, retrievers, Tavily tools, FAISS initialization
â”‚   â””â”€â”€ utils.py                    # Helper functions
â”‚
â”œâ”€â”€ Data/                           # Datasets
â”‚   â”œâ”€â”€ FACTors.csv                 # FACTors dataset (fact-checked claims)
â”‚   â””â”€â”€ content_bias_scores.csv     # Bias scores from the FACTors project
â”‚
â”œâ”€â”€ EUfactcheckData/                # EUfactcheck scraping and data
â”‚   â”œâ”€â”€ scrape_eufactcheck.py       # Scraping scripts
â”‚   â””â”€â”€ data/                       # Scraped EUfactcheck articles and claims
â”‚
â”œâ”€â”€ Evaluation/                     # Evaluation and validation
â”‚   â”œâ”€â”€ app_validate.py             # Streamlit app for manual reference validation
â”‚   â”œâ”€â”€ app_compare.py              # Streamlit app for output comparison
â”‚   â”œâ”€â”€ validated_reference.ipynb   # Reference set creation pipeline
â”‚   â”œâ”€â”€ validated_reference_data.csv# Final validated reference dataset
â”‚   â”œâ”€â”€ llm_as_judge.ipynb           # LLM-as-judge evaluation
â”‚   â””â”€â”€ measure_latency.ipynb       # Latency benchmarking
â”‚
â”œâ”€â”€ notebooks/                      # Research and analysis notebooks
â”‚   â”œâ”€â”€ Create-faiss.ipynb          # FAISS embedding creation
â”‚   â””â”€â”€ Explore_data_bias.ipynb     # Bias data exploration
â”‚
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # Project documentation
